{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut # esta librer√≠a tiene funciones para poder obtener un procesamiento del <T,H>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#arr = np.array([[1, 4, 2, 5, 3],[1, 4, 2, 5, 3]])\n",
    "#indices = len(np.where(arr > 2.5)[0])\n",
    "#print(indices)  # Salida: (array([1, 3]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/rit/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\") # modelo de nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.load_vectors_in_lang(nlp,\"./data/numberbatch-en-17.04b.txt\") # carga de vectores en nlp.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = [\"A brown and white dog is resting in the grass\"]\n",
    "hipotesis = [\"A brown and white dog is running through the tall grass\"]\n",
    "clases = [\"CONTRADICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A brown and white dog is resting in the grass\n",
      "A brown and white dog is running through the tall grass\n",
      "       brown  white  dog  run  tall  grass\n",
      "brown    1.0    0.5  0.1  0.0   0.2    0.1\n",
      "white    0.5    1.0  0.0  0.0   0.2    0.1\n",
      "dog      0.1    0.0  1.0  0.1   0.0    0.1\n",
      "rest     0.0    0.0  0.0  0.1   0.0    0.0\n",
      "grass    0.1    0.1  0.1  0.0   0.2    1.0\n",
      "Tokens de H:  Index(['brown', 'white', 'dog', 'run', 'tall', 'grass'], dtype='object')\n",
      "Tokens de T:  Index(['brown', 'white', 'dog', 'rest', 'grass'], dtype='object')\n",
      "Entropia de ma:  2.039\n",
      "(5, 6)\n",
      "brown\n",
      "Valores de 0 dado T:  [1.  0.5 0.1 0.  0.1]\n",
      "Entropia de 0 dado T:  1.922\n",
      "Diferencia H(T,H)- H(h,T) 0.11700000000000021\n",
      "0 Entropia de  [1.  0.5 0.1 0.  0.1]  incrementando h 0  : 1.922\n",
      "white\n",
      "Valores de 1 dado T:  [0.5 1.  0.  0.  0.1]\n",
      "Entropia de 1 dado T:  1.922\n",
      "Diferencia H(T,H)- H(h,T) 0.11700000000000021\n",
      "1.922 Entropia de  [1.  0.5 0.1 0.  0.1 0.5 1.  0.  0.  0.1]  incrementando h 1  : 1.971\n",
      "dog\n",
      "Valores de 2 dado T:  [0.1 0.  1.  0.  0.1]\n",
      "Entropia de 2 dado T:  1.522\n",
      "Diferencia H(T,H)- H(h,T) 0.5170000000000001\n",
      "1.971 Entropia de  [1.  0.5 0.1 0.  0.1 0.5 1.  0.  0.  0.1 0.1 0.  1.  0.  0.1]  incrementando h 2  : 1.909\n",
      "run\n",
      "Valores de 3 dado T:  [0.  0.  0.1 0.1 0. ]\n",
      "Entropia de 3 dado T:  0.971\n",
      "Diferencia H(T,H)- H(h,T) 1.068\n",
      "1.909 Entropia de  [1.  0.5 0.1 0.  0.1 0.5 1.  0.  0.  0.1 0.1 0.  1.  0.  0.1 0.  0.  0.1\n",
      " 0.1 0. ]  incrementando h 3  : 1.802\n",
      "tall\n",
      "Valores de 4 dado T:  [0.2 0.2 0.  0.  0.2]\n",
      "Entropia de 4 dado T:  0.971\n",
      "Diferencia H(T,H)- H(h,T) 1.068\n",
      "1.802 Entropia de  [1.  0.5 0.1 0.  0.1 0.5 1.  0.  0.  0.1 0.1 0.  1.  0.  0.1 0.  0.  0.1\n",
      " 0.1 0.  0.2 0.2 0.  0.  0.2]  incrementando h 4  : 2.069\n",
      "grass\n",
      "Valores de 5 dado T:  [0.1 0.1 0.1 0.  1. ]\n",
      "Entropia de 5 dado T:  1.371\n",
      "Diferencia H(T,H)- H(h,T) 0.6680000000000001\n",
      "2.069 Entropia de  [1.  0.5 0.1 0.  0.1 0.5 1.  0.  0.  0.1 0.1 0.  1.  0.  0.1 0.  0.  0.1\n",
      " 0.1 0.  0.2 0.2 0.  0.  0.2 0.1 0.1 0.1 0.  1. ]  incrementando h 5  : 2.039\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(textos)):\n",
    "    print(textos[i])\n",
    "    print(hipotesis[i])\n",
    "    t_lem_temp=ut.get_lemmas_(textos[i],nlp)\n",
    "    h_lem_temp=ut.get_lemmas_(hipotesis[i],nlp)\n",
    "    t_lem=[]\n",
    "    h_lem=[]\n",
    "    for a in t_lem_temp:\n",
    "        if a not in t_lem:\n",
    "            t_lem.append(a)\n",
    "    for a in h_lem_temp:\n",
    "        if a not in h_lem:\n",
    "            h_lem.append(a)\n",
    "    t_vectors=ut.get_matrix_rep2(t_lem, nlp, normed=False)\n",
    "    h_vectors=ut.get_matrix_rep2(h_lem, nlp, normed=False)\n",
    "    t_vectors_n=ut.get_matrix_rep2(t_lem, nlp, normed=True)\n",
    "    h_vectors_n=ut.get_matrix_rep2(h_lem, nlp, normed=True)\n",
    "    \n",
    "    # # Obtencion de matriz de alineamiento, matriz de move earth y mutual information\n",
    "    redondeo=1\n",
    "    ma_n=np.dot(t_vectors_n,h_vectors_n.T)\n",
    "    ma_n = np.clip(ma_n, 0, 1).round(redondeo)\n",
    "    ma=pd.DataFrame(ma_n,index=t_lem,columns=h_lem)\n",
    "    print(ma)\n",
    "    print(\"Tokens de H: \",ma.columns)\n",
    "    print(\"Tokens de T: \",ma.index)\n",
    "    H_T_H = ut.entropia(ma.values.flatten())\n",
    "    print(\"Entropia de ma: \",H_T_H)\n",
    "    print(ma_n.shape)\n",
    "    hs=np.array([])\n",
    "    ent_anterior=0\n",
    "    cambio=0\n",
    "    for i in range(ma_n.shape[1]):\n",
    "        print(ma.columns.values[i])\n",
    "        hk=ma_n[:,i].flatten()\n",
    "        print(\"Valores de\",i, \"dado T: \",hk)\n",
    "        H_h_T = ut.entropia(ma_n[:,i].flatten())\n",
    "        print(\"Entropia de\",i, \"dado T: \",H_h_T)\n",
    "        print(\"Diferencia H(T,H)- H(h,T)\",H_T_H-H_h_T)\n",
    "        hs = np.append(hs,hk)\n",
    "        ent_hs= ut.entropia(hs)\n",
    "        if (ent_anterior>ent_hs):\n",
    "            cambio+=1\n",
    "        print(ent_anterior,\"Entropia de \",hs, \" incrementando h\",i,\" :\",ent_hs)\n",
    "        ent_anterior=ent_hs\n",
    "    print(cambio)\n",
    "    # print(\"run\",ut.entropia(ma[[\"run\"]].values.flatten()))\n",
    "    # print(\"brown\",ut.entropia(ma[[\"brown\"]].values.flatten()))\n",
    "    # print(\"brown white\",ut.entropia(ma[[\"brown\",\"white\"]].values.flatten()))\n",
    "    # print(\"brown white dog\",ut.entropia(ma[[\"brown\",\"white\",\"dog\"]].values.flatten()))\n",
    "    # print(\"brown white dog run\",ut.entropia(ma[[\"brown\",\"white\",\"dog\",\"run\"]].values.flatten()))\n",
    "    # print(\"brown white dog run tall\",ut.entropia(ma[[\"brown\",\"white\",\"dog\",\"run\",\"tall\"]].values.flatten()))\n",
    "    # print(\"brown white dog run tall grass\",ut.entropia(ma[[\"brown\",\"white\",\"dog\",\"run\",\"tall\", \"grass\"]].values.flatten()))\n",
    "    # print(\"brown white dog tall grass\",ut.entropia(ma[[\"brown\",\"white\",\"dog\",\"tall\", \"grass\"]].values.flatten()))\n",
    "    # print(\"brown white dog grass\",ut.entropia(ma[[\"brown\",\"white\",\"dog\",\"grass\"]].values.flatten()))\n",
    "    # print(\"-----------------------------------------\")\n",
    "    # for i in range(ma_n.shape[0]):\n",
    "    #     print(ma.index.values[i])\n",
    "    #     hk=ma_n[i].round(redondeo).flatten()\n",
    "    #     print(\"Valores de\",i, \"dado H: \",hk)\n",
    "    #     H_h_T = ut.entropia(ma_n[i].round(redondeo).flatten())\n",
    "    #     print(\"Entropia de\",i, \"dado H: \",H_h_T)\n",
    "    #     print(\"Diferencia H(T,H)- H(t,H)\",H_T_H-H_h_T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stopwords(frase,nlp):\n",
    "    stops=set()\n",
    "    doc = nlp(frase)\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #        token.shape_, token.is_alpha, token.is_stop)\n",
    "            stops.add(token.lemma_)\n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_stopwords=set()\n",
    "for j in range(45):\n",
    "    prueba=pd.read_csv(\"../OPENAI/data/SICK/TRAIN_\"+str(j+1)+\".csv\")\n",
    "    textos = prueba[\"sentence1\"].to_list()       # almacenamiento en listas\n",
    "    hipotesis = prueba[\"sentence2\"].to_list()\n",
    "    clases = prueba[\"gold_label\"].to_list()\n",
    "    for i in range(len(textos)):\n",
    "        #print(textos[i])\n",
    "        conjunto_stopwords.update(find_stopwords(textos[i],nlp))\n",
    "        conjunto_stopwords.update(find_stopwords(hipotesis[i],nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'s\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'before',\n",
       " 'behind',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'between',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'by',\n",
       " 'call',\n",
       " 'can',\n",
       " 'do',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'empty',\n",
       " 'few',\n",
       " 'five',\n",
       " 'for',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'go',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'in',\n",
       " 'into',\n",
       " 'it',\n",
       " 'its',\n",
       " 'make',\n",
       " 'many',\n",
       " 'mostly',\n",
       " 'next',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'out',\n",
       " 'over',\n",
       " 'part',\n",
       " 'put',\n",
       " 'really',\n",
       " 'same',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'show',\n",
       " 'side',\n",
       " 'some',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'still',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'themselves',\n",
       " 'there',\n",
       " 'they',\n",
       " 'this',\n",
       " 'three',\n",
       " 'through',\n",
       " 'to',\n",
       " 'together',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'two',\n",
       " 'under',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'use',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'with',\n",
       " 'without',\n",
       " 'you'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conjunto_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
